<!DOCTYPE html>
<html>

<head>
    <meta charset="UTF-8">
    <title>aPPle!</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/0.9.0/p5.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/0.9.0/addons/p5.dom.min.js"></script>
    <script src="https://unpkg.com/ml5@0.3.1/dist/ml5.min.js" type="text/javascript"></script>

    <!-- <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.1.2/dist/tf.min.js"></script>
    <script src="https://storage.googleapis.com/tm-pro/v0.6.4/teachablemachine-image.min.js"></script>
    <script type="text/javascript">
        // Full API: https://github.com/googlecreativelab/teachablemachine-libraries

        // the json file (model topology) has a reference to the bin file (model weights)
        const checkpointURL = 'https://storage.googleapis.com/tm-mobilenet/applejpl2/model.json';
        // the metatadata json file contains the text labels of your model and additional information
        const metadataURL = 'https://storage.googleapis.com/tm-mobilenet/applejpl2/model.json';

        let model; let webcamEl; let maxPredictions;

        async function init() {
            // load the model and metadata
            // Refer to tmImage.loadFromFiles() in the API to support files from a file picker 
            // or files from your local hard drive
            model = await tmImage.load(checkpointURL, metadataURL);
            maxPredictions = model.getTotalClasses();

            // optional function for creating a webcam
            // webcam has a square ratio and is flipped by default to match training
            const webcamFlipped = true;
            webcamEl = await tmImage.getWebcam(200, 200, 'front', webcamFlipped);
            webcamEl.play();
            document.body.appendChild(webcamEl);

            window.requestAnimationFrame(loop); // kick of pose prediction loop
        }

        async function loop(timestamp) {
            await predict();
            window.requestAnimationFrame(loop);
        }

        async function predict() {
            // predict can take in an image, video or canvas html element
            // we set flip to true since the webcam was only flipped in CSS
            const flip = true;
            const prediction = await model.predict(webcamEl, flip, maxPredictions);
            console.log(prediction);
        }

        init();
    </script> -->

    <link rel="stylesheet" href="style.css">
</head>

<body>
    <script src="sketch.js"></script>
    <script src="things.js"></script>
    <script src="time.js"></script>
    <script src="helper.js"></script>
</body>

</html>